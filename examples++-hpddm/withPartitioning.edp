//  run with MPI:  ff-mpirun -np 2 script.edp
// NBPROC 2

macro partitioner()scotch// EOM     // metis, scotch, or parmetis
macro dimension()3// EOM            // 2D or 3D
include "macro_ddm.idp"             // additional DDM functions

macro def(i)i// EOM                         // scalar field definition
macro init(i)i// EOM                        // scalar field initialization
macro def2(i)[i, i#B]// EOM
macro init2(i)[i, i]// EOM
func Pk = P1;                               // finite element space
func Zk = [P1, P2];                         // finite element space

meshN Th = cube(1, 1, 1);
fespace Wh(Th, Pk);                          // local finite element space
fespace Qh(Th, Zk);                          // local finite element space
int[int] arrayIntersection;                  // ranks of neighboring subdomains
int[int][int] restrictionIntersectionP(0);   // local-to-neighbors renumbering
int[int][int] restrictionIntersectionZ(0);   // local-to-neighbors renumbering
real[int] DP;                                // partition of unity
real[int] DZ;                                // partition of unity
{
    int[int] l = [1, 1, 1, 1];
    meshN ThBorder, ThGlobal = cube(getARGV("-global", 5), getARGV("-global", 5), getARGV("-global", 5));    // global mesh
    fespace Ph(ThGlobal, P0);
    real[int] part(Ph.ndof);
    if(mpirank == 0)
        partitionerSeq(part, ThGlobal, mpisize);
    buildWithPartitioning(Th, ThBorder, ThGlobal, part, 11111, 1, 1, DP, arrayIntersection, restrictionIntersectionZ, Wh, Pk, mpiCommWorld, false);
    ThGlobal = cube(getARGV("-global", 5), getARGV("-global", 5), getARGV("-global", 5)); // need to reload the global mesh because it is destroyed in ''build*''
    buildEdgeWithPartitioning(Th, ThBorder, ThGlobal, part, 22222, 1, 1, DZ, arrayIntersection, restrictionIntersectionP, Qh, Zk, mpiCommWorld, false, Zk, def2, init2);
    ThBorder = cube(1, 1, 1);
}
